# Udacity Final Project--Sparkify


## Project Backgound
### Motivations
Developing Skills of:  
1. Loading large datasets into Spark and manipulating them using Spark SQL and Spark Dataframes
2. Using the machine learning APIs within Spark ML to build and tune models
3. Integrating the skills I've learned in the Spark course and the Data Scientist Nanodegree program

### Task and Datasets 
The goal is to predict churned users based on activites and attributes data of them. And deploy the solution on a distributed system.
The size of original datasets is 12GB. Due to the limited computation power of free version of IBM Cloud, a medium-sized sub-datasets is utilized.  



## Summary of Project
Procedures of analysis:  
1. Data cleaning
2. Data exploration
3. Feature engineering
4. Modelling

Results:  
Only model used here is logistice regression and tested. Currently the model is giving only 72% accuracy which can be worked upon to make it more.


## Acknowledgement
This dataset is provided bu the Udacity team with some instruction to accomplish the project.
